{"title":"Referring Expression Generation through Attribute-Based Heuristics\n","id":"W09-0609","citations":"In a similar vein , Viethen and Dale -LRB- -RRB- examine how similar references produced by well-known algorithms are to human-produced references , and Dale and Viethen -LRB- -RRB- examine differences in human behavior when generating referring expressions .\n","body":"1 Introduction The last few years have witnessed a considerable move towards empiricism in referring expression generation ; this is evidenced both by the growing body of work that analyses and tries to replicate the content of corpora of human-produced referring expressions , and particularly by the significant participation in the TUNA and GREC challenge tasks built around such activities -LRB- see , for example , -LRB- Belz and Gatt , 2007 ; Belz et al. , 2008 ; Gatt et al. , 2008 -RRB- -RRB- .\nOne increasingly widespread observation -- obvious in hindsight , but surprisingly absent from much earlier work on referring expression generation -- is that one person \u0027s referential behaviour differs from that of another : given the same referential task , different subjects will choose different referring expressions to identify a target referent .\nFaced with this apparent lack of cross-speaker consistency in how to refer to entities , we might question the validity of any exercise that tries to develop an algorithm on the basis of data from multiple speakers .\nIn this paper we revisit the corpus of data that was introduced and discussed in -LRB- Viethen and Dale , 2008a ; Viethen and Dale , 2008b -RRB- with the objective of determining what referential behaviour , if any , might be learned automatically from the data .\nWe find that , despite the apparent diversity of the data when we consider the production of referring expressions across subjects , a closer examination reveals that individual attributes within referring expressions do appear to be selected on the basis of contextual factors with a high degree of consistency .\nThis suggests that referring behaviour might be best thought of as consisting of a combination of lower-level heuristics , with each individual \u0027s overall referring behaviour being constructed from a potentially distinct combination of these common heuristics .\nIn Section 2 we describe the corpus we use for the experiments in this paper .\nIn Section 3 we explore to what extent we can use this corpus to learn an algorithm for referring expression generation ; in Section 4 we look more closely at the nature of individual variation within the corpus .\nSection 5 briefly discusses related work on the use of machine learning in referring expression generation , and Section 6 draws some conclusions and points to future work .\n2 The Corpus The corpus we use was collected via a data gathering experiment described in -LRB- Viethen and Dale , 2008a ; Viethen and Dale , 2008b -RRB- .\nThe purpose of the data gathering was to gain some insight into how human subjects use relational referring expressions , a relatively unexplored aspect of referring expression generation .\nParticipants visited a website , where they first saw an introductory page with a set of simple instructions and a sample stimulus scene consisting of three objects .\nEach participant was then assigned one of two trial sets of ten scenes each ; the two trial sets are superficially different , but the elements of the sets are pairwise identical in terms of the factors explored in the research .\nThe complete set of 20 scenes is shown in Figure 1 , where Trial Set 1 consists of Scenes 1 through 10 , and Trial Set 2 consists of Scenes 11 through 20.1 The scenes were presented successively in a preset order , which was the same for each participant .\nBelow each scene , the participant had to complete the sentence Please pick up the ... in a text box before clicking on a button to see the next scene .\nThe task was to describe the target referent in the scene -LRB- marked by a grey arrow -RRB- in a way that would enable a friend looking at the same scene to pick it out from the other objects .\nThe experiment was completed by 74 participants from a variety of different backgrounds and ages ; most were university-educated and in their early or mid twenties .\nFor reasons discussed in -LRB- Viethen and Dale , 2008b -RRB- , the data of 11 participants was discarded .\nOf the remaining 63 participants , 29 were female , while 34 were male .\nThe design of the stimuli used in the experiment is described in detail in -LRB- Viethen and Dale , 2008a -RRB- .\nScene 1 is paired with Scene 11 , Scene 2 with Scene 12 , and so on ; in each pair , the only differences are the colour scheme used and the left -- right orientation , with these variations being introduced to make the experiment less monotonous for subjects ; -LRB- Viethen and Dale , 2008a -RRB- report that these characteristics of the scenes appear to have no significant effect on the forms of reference used .\nthe stimulus scenes .\nWe provide a summary of the key points here .\nIn order to explore even the most basic hypotheses with respect to the use of relational expressions , which was the aim of the original study , scenes containing at least three objects were required .\nOne of these objects is the intended referent , which is referred to here as the target .\nThe subject has to describe the target in such a way as to distinguish it from the other two objects in the scene .\nAlthough the scenes presented to the subjects are such that spatial relations are never necessary to distinguish the target , they are set up so that one of the two non-target objects was clearly closer to the target .\nThis object is referred to as the -LRB- potential -RRB- landmark ; and we call the third object in the scene the distractor .\nTo minimise the number of variables in the experiments , scenes are restricted to only two kinds of objects , cubes and balls .\nThe objects also vary in two dimensions : colour -LRB- either green , blue , yellow , or red -RRB- ; and size -LRB- either large or small -RRB- .\nTo further reduce the number of factors in the scene design , the landmark and distractor are always placed clearly side by side , and the target is located on top of or directly in front of the landmark .\nFinally , to reduce the set of possible stimuli to a manageable number , five schemata -LRB- see Figure 2 -RRB- were created as a basis for the final stimulus set .\nThe design of these schemata was informed by a number of research questions with regard to the use of relations ; see -LRB- Viethen and Dale , 2008b -RRB- .\nA schema determines the type and size of each object in the scenes that are based on it , and determines which objects share colour .\nSo , for example , in scenes based on Schema C , the target is a small ball ; the landmark is a large cube with different colour from the target ; and the distractor is a large ball sharing its colour with the target .\nA htg col , tg typei the blue cube B htg col , tg type , rel , lm col , lm typei the blue cube in front of the red ball C htg col , tg type , rel , lm size , lm col , lm typei the blue cube in front of the large red ball D htg col , tg type , rel , lm size , lm typei the blue cube in front of the large ball E htg col , tg type , rel , lm typei the blue cube in front of the ball F htg size , tg col , tg typei the large blue cube G htg size , tg col , tg type , rel , lm col , lm typei the large blue cube in front of the red ball H htg size , tg col , tg type , rel , lm size , lm col , lm typei the large blue cube in front of the large red ball I htg size , tg col , tg type , rel , lm size , lm typei the large blue cube in front of the large ball J htg size , tg col , tg type , rel , lm typei the large blue cube in front of the ball K htg size , tg typei the large cube L htg size , tg type , rel , lm size , lm typei the large cube in front of the large ball M htg size , tg type , rel , lm typei the large cube in front of the ball N htg typei the cube O htg type , rel , lm col , lm typei the cube in front of the red ball P htg type , rel , lm size , lm col , lm typei the cube in front of the large red ball Q htg type , rel , lm size , lm typei the cube in front of the large ball R htg type , rel , lm typei the cube in front of the ball GRE3D3 corpus .\nFrom each schema , four distinct scenes were generated , resulting in the 20 stimulus scenes shown in Figure 1 .\nAs noted above , there are really only 10 distinct ` underlying \u0027 scene types here , so in the remainder of this paper we will talk in terms of Scenes 1 through 10 , where the data from the pairwise matched scenes are conflated .\nBefore conducting any quantitative data analysis , some syntactic and lexical normalisation was carried out on the data provided by the participants .\nIn particular , spelling mistakes were corrected ; normalised names were used for colour values and head nouns -LRB- for example , box was replaced by cube -RRB- ; and complex syntactic structures such as relative clauses were replaced with semantically equivalent simpler ones such as adjectives .\nThese normalisation steps should be of no consequence to the analysis presented here , since we are solely interested in exploring the semantic content of referring expressions , not their lexical and syntactic surface structure .\nFor the purposes of the machine learning experiments described in this paper , we made a few further changes to the data set in order to keep the number of properties and their possible values low .\nWe removed locative expressions that made referThe data set resulting from the experiment described above is known as the GRE3D3 Corpus ; the name stands for ` Generation of Referring Expressions in 3D scenes with 3 Objects \u0027 .\nence to a part of the scene -LRB- 58 instances -RRB- and references to size as the same -LRB- 4 instances -RRB- ; so , for example , the blue cube on top of the green cube in the right and the blue cube on top of the green cube of the same size both became the blue cube on top of the green cube .\nWe also removed the mention of a third object from ten descriptions in order to keep the number of possible objects per description to a maximum of two .\nThese changes resulted in seven descriptions no longer satisfying the criterion of being fully distinguishing , so we removed these descriptions from the corpus .\n3 Learning Description Patterns The resulting corpus consists of 623 descriptions .\nEvery one of these is an instance of one of the 18 patterns shown in Table 1 ; for ease of reference , we label these patterns A through R. Each pattern indicates the sequence of attributes used in the description , where each attribute is identified by the object it describes -LRB- tg for target , lm for landmark -RRB- and the attribute used -LRB- col , size and type for colour , size and type respectively -RRB- .\nMost work on referring expression generation attempts to determine what attributes should be used in a description by taking account of aspects of the context of reference .\nAn obvious question is then whether we can learn the description patterns in this data from the contexts in which they were produced .\nTo explore this , we chose to capture the relevant aspects of context by means of the notion of characteristics of scenes .\nThe characteristics of scenes which we hypothesize might have an impact on the choice of referential form are those summarised in Table 2 ; these are precisely the characteristics that were manipulated in the design of the schemata in Figure 2 .\nOf course , there is no one correct answer for how to refer to the target in any given scene .\nFigure 3 shows the distribution of different patterns across the different scenes ; so , for example , some scenes -LRB- Scenes 4 , 5 , 9 and 10 -RRB- result in only five semantically distinct referring expression forms , whereas Scene 7 results in 12 distinct referring expression forms .\nAll of these are distinguishing descriptions , so all are acceptable forms of reference , although some contain more redundancy than others .\nMost obvious from the chart is that , for many scenes , there is a predominant form of reference used ; so , for example , pattern F -LRB- htg size , tg col , tg typei -RRB- accounts for 43 -LRB- 68 % -RRB- of the descriptions used in Scene 4 , and pattern A -LRB- htg col , tg typei -RRB- is very frequently used in a number of scenes .3 We used Weka -LRB- Witten and Eibe , 2005 -RRB- with the J48 decision tree classifer to see what correspondences might be learned between the characterisics of the scenes listed in Table 2 and the forms of referring expression used for the target referents , as shown in Table 1 .\nThe pruned decision tree learned by this method predicted the actual form of reference used in only 48 % of cases under 10-fold cross-validation , but given that there are many ` gold standard \u0027 descriptions for each scene , The chart as presented here is obviously too small to enable detailed examination , and our use of colour coding will be of no value in a monchrome rendering of the paper ; however , the overall shape of the data is sufficient to demonstrate the points we make here .\nthis low score is hardly surprising ; a mechanism which learns only one answer will inevitably be ` wrong \u0027 in many cases .\nMore revealing , however , is the rule learned from the data : if tg type \u003d dr type then use F -LRB- htg size , tg col , tg typei -RRB- else use A -LRB- htg col , tg typei -RRB- endif terns in the data , and indeed one or other appears at least once in the human data for each scene ; consequently , the learned rule is able to produce a ` correct \u0027 answer for every scene .4 4 Individual Variation One of the most striking things about the data in this corpus is the extent to which different subjects appear to do different things when they construct referring expressions , as demonstrated by the distribution of patterns in Figure 3 .\nAnother way of looking at this variation is to characterise the behaviour of each subject in terms of the sequence of descriptions they provide in response to the set of 10 stimuli .\nAcross the 63 subjects , there are 47 different sequences ; of these , only four occur more than once -LRB- in other words , 43 subjects did not produce the same sequence of descriptions for the ten scenes as anyone else -RRB- .\nThe recurrent sequences , i.e. those used by at least two people , are shown in Table 3 .\nNote that the most frequently recurring sequence , The fact that the rule is conditioned on a property of the distractor object may be an artefact of the stimulus set construction ; this would require a more diverse set of scenes to determine .\nof the bar indicates how often each of the 18 patterns is used .\nwhich matches the behaviour of nine separate subjects , consists only of uses of patterns A and F .\nIt remains to be seen to what extent a larger data set would demonstrate more convergence ; however , the point to be made at present is that any attempt to predict the behaviour of a given speaker by means of a model of referring behaviour is going to have to take account of a great deal of indiviual variation .\nNonetheless , we re-ran the J48 classifier described in the previous section , this time using the participant ID as well as the scene characteristics in Table 2 as features .\nThis improved pattern prediction to 57.62 % .\nThis suggests that individual differences may indeed be capturable from the data , although we would need more data than the mere 10 examples we have from each subject to learn a good predictive model .\nIn the face of this lack of data , another approach is to look for commonalities in the data in terms of the constituent elements of the different reference patterns used for each scene .\nThis way of thinking about the data was foreshadowed by -LRB- Viethen and Dale , 2008b -RRB- , who observed that the subjects could be separated into those who always used relations , those who never used relations , and those who sometimes used relations .\nThis leads us to consider whether there are characteristics of scenes or speakers which are highly likely to result in specific attributes being used in descriptions .\nIf this is the case , a decision tree learner should be able to learn for each individual attribute whether it should be included in a given situation .\nAn appropriate baseline for any experiments here is the success rate of simply including or not including each attribute -LRB- basically a 0-R majority class classifier -RRB- , irrespective of the characteristics of the scene .\nTable 4 compares the results for this ` context-free \u0027 approach with one model that is trained on the characteristics of scenes , and another that takes both the characteristics of scenes and the participant ID into account .5 Interestingly , the ` context-free \u0027 strategies work suprisingly well for predicting the inclusion of some attributes in the human data .\nAs has been noted in other work -LRB- see for example -LRB- Viethen et al. , 2008 -RRB- -RRB- , colour is often included in referring expressions irrespective of its discriminatory power , and this is borne out by the data here .\nPerhaps more suprising is the large degree to which the inclusion of landmark size is captured by a contextfree strategy .\nAs before , the results reported are for the accuracy of a pruned J48 decision tree , under 10-fold cross-validation .\nImprovement on all attribues other than target colour improves when we take into account the characteristics of the scenes , consistent with our assumptions that context does matter .\nWhen we add participant ID to the features used in the learner , performance improves further still , indicating that there are speaker-specific consistencies in the data .\nIt is instructive to look at the rules learned on the basis of the scene characteristics .\nNot surprisingly , the rule derived for target colour inclusion is simply to always include the colour -LRB- i.e. , the same context-free colour inclusion rule that proves most effective in modelling the data without reference to scene characteristics -RRB- .\nThe rules for including the other attributes on the basis of scene characteristics -LRB- but not participant ID -RRB- are shown in Figure 4 .\nThe rules learned when we include participant ID are more conplex , but can be summarised in a way that demonstrates how this approach can reveal something about the variety of ways in which speakers appear to approach the task of referring expression generation .\nFocussing , as an example , just on the question of whether or not to use the target object \u0027s colour in a referring expression , we find the following : • 48 participants always used colour , irrespective of the context -LRB- this corresponds to the baseline rule learned above -RRB- .\n• The other participants always use colour if the target and the landmark are of the same type -LRB- which again is intuitively quite appropriate -RRB- .\n• When the landmark and the target are not of the same type , we see more variation in behaviour ; 19 participants simply do n\u0027t use colour , and the behaviour of seven can be captured via a more complex analysis : four use colour if the target and the distractor are the same size , two use colour if the target and distractor are of the same size and the target is on top of the landmark , and one uses colour if the target and distractor share colour .\nAgain , the specific details of the rules learned here are probably not particularly significant , based as they are on a limited data set and a set of stimuli that may give elevated status to incidental properties .\nHowever , the general point remains that we if tg type \u003d dr type then include tg size Relation : if rel \u003d on top of and lm size \u003d dr size then include rel if we have used a relation then include lm col if we have used a relation and tg col \u003d lm col can use this kind of analysis to identify possible rules for the inclusion of individual attributes in referring expressions .\nWhat this suggests is that we might be able to capture the behaviour of individual speakers not in terms of an overall strategy , but as a composite of heuristics , where each heuristic accounts for the inclusion of a specific attribute .\nThe rules , or heuristics , shown in Figure 4 are just those which are most successful in predicting the data ; but there can be many other rules that might be used for the inclusion of particular attributes .\nSo , for example , I might be the kind of speaker who just automatically includes the colour of an intended referent without any analysis of the scene ; and I might be the kind of speaker who always uses a relation to a nearby landmark in describing the intended referent .\nOr I might be the kind of speaker who surveys the scene and takes note of whether the landmark \u0027s colour is distinctive ; and so on .\nThought of in this way , each speaker \u0027s approach to reference is like a set of ` parallel gestalts \u0027 that contribute information to the description being constructed .\nThe particular rules for inclusion that any speaker uses might vary depending on their personal past history , and perhaps even on the basis of situation-specific factors that on a given occasion might lean the speaker towards either being ` risky \u0027 or ` cautious \u0027 -LRB- Carletta , 1992 -RRB- .\nAs alluded to earlier , the specific content of the rules shown in Figure 4 may appear idiosyncratic ; they are just what the limited data in the corpus Pattern Sequence -LRB- hScene # , DescriptionPatterni -RRB- Number of subjects h1 , Ai , h2 , Ai , h3 , Gi , h4 , Fi , h5 , Ai , h6 , Ai , h7 , Ai , h8 , Gi , h9 , Fi , h10 , Ai 2 h1 , Bi , h2 , Bi , h3 , Gi , h4 , Hi , h5 , Bi , h6 , Bi , h7 , Bi , h8 , Gi , h9 , Hi , h10 , Bi 2 h1 , Ni , h2 , Ni , h3 , Ki , h4 , Fi , h5 , Ai , h6 , Ni , h7 , Ni , h8 , Ki , h9 , Fi , h10 , Ai 6 h1 , Ai , h2 , Ai , h3 , Fi , h4 , Fi , h5 , Ai , h6 , Ai , h7 , Ai , h8 , Fi , h9 , Fi , h10 , Ai 9 supports , and some elements of the rules may be due to artefacts of the specific stimuli used in the data gathering .\nWe would require a more diverse set of stimuli to determine whether this is the case , but the basic point stands : we can find correlations between characteristics of the scenes and the presence or absence of particular attributes in referring expressions , even if we can not predict so well the particular combinations of these correlations that a given speaker will use in a given situation .\n5 Related Work There is a significant body of work on the use of machine learning in referring expression generation , although typically focussed on aspects of the problem that are distinct from those considered here .\nIn the context of museum item descriptions , Poesio et al. -LRB- 1999 -RRB- explore the decision of what type of referring expression NP to use to refer to a given discourse entity , using a statistical model to choose between using a proper name , a definite description , or a pronoun .\nMore recently , Stoia et al. -LRB- 2006 -RRB- attempt a similar task , but this time in an interactive navigational domain ; as well as determining what type of referring expression to use , they also try to learn whether a modifier should be included .\nCheng et al. -LRB- 2001 -RRB- try to learn rules for the incorporation of non-referring modifiers into noun phrases .\nA number of the contributions to the 2008 GREC and TUNA evaluation tasks -LRB- Gatt et al. , 2008 -RRB- have made use of machine learning techniques .\nThe GREC task is primarily concerned with the choice of form of reference -LRB- i.e. whether a proper name , a descriptive NP or a pronoun should be used -RRB- , and so is less relevant to the focus of the present paper .\nMuch of the work on the TUNA Task is relevant , however , since this also is concerned with determining the content of referring expressions in terms of the attributes used to build a distinguishing description .\nIn particular , Fabbrizio et al. -LRB- 2008 -RRB- explore the impact of individual style and priming on attribute selection for referring expression generation , and Bohnet -LRB- 2008 -RRB- uses a nearestneighbour learning technique to acquire an individual referring expression generation model for each person .\nOther related approaches to attribute selection in the context of the TUNA task are explored in -LRB- Gerv ´ as et al. , 2008 ; de Lucena and Paraboni , 2008 ; Kelleher and Mac Namee , 2008 ; King , 2008 -RRB- .\n6 Conclusions We know that people \u0027s referential behaviour varies significantly .\nDespite this apparent variation , we have demonstrated above that there does appear to be a reasonable correlation between characteristics of the scene and the incorporation of particular attributes in a referring expression .\nOne way to conceptualise this is that the decision as to whether or not to incorporate a given feature such as colour or size may vary from speaker to speaker ; this is evidenced by the data .\nWe might think of these as individual reference strategies ; a good example of such a strategy , widely attested across many experiments , is the decision to include colour in a referring expression independent of its discriminatory power , perhaps because it is an easily perceivable and often-useful attribute .\nThe overall approach to reference that is demonstrated by a given speaker then consists of the gathering together of a number of strategies ; the particular combinations may vary from speaker to speaker , but as is demonstrated by the analysis in this paper , some of the strategies are widely used .\nIn current work , we are gathering a much larger data set using more complex stimuli .\nThis will allow the further development and testing of the basic ideas proposed in this paper as well as their integration into a full referring expression generation algorithm .\nReferences\n","abstr":"Abstract\nIn this paper , we explore a corpus of\nhuman-produced referring expressions to\nsee to what extent we can learn the referential behaviour the corpus represents .\nDespite a wide variation in the way subjects\nrefer across a set of ten stimuli , we demonstrate that component elements of the referring expression generation process appear to generalise across participants to a\nsignificant degree .\nThis leads us to propose an alternative way of thinking of referring expression generation , where each\nattribute in a description is provided by a\nseparate heuristic .\n"}
